id,标题,模型,时间,期刊/会议,CCF等级,原文,翻译,代码
1,Tacotron: Towards End-to-End Speech Synthesis,Tacotron,2017.03,Interspeech,C,https://arxiv.org/abs/1703.10135,https://blog.csdn.net/weixin_42721167/article/details/113406997,https://github.com/linslime/tacotron
,Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions,Tacotron2,2018,ICASSP,B,https://arxiv.org/abs/1712.05884,https://blog.csdn.net/weixin_43916891/article/details/127463829https://blog.csdn.net/weixin_42721167/article/details/114377171,https://github.com/linslime/Tacotron2-PyTorch
,"FastSpeech: Fast, Robust and Controllable Text to Speech",FastSpeech,2019,NeurIPS,A,https://arxiv.org/abs/1905.09263,https://blog.csdn.net/weixin_42721167/article/details/118226439,https://github.com/linslime/FastSpeech
,FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,FastSpeech2,2021,ICLR,,https://arxiv.org/abs/2006.04558,https://blog.csdn.net/weixin_42721167/article/details/118226439,https://github.com/linslime/FastSpeech2
,Neural Speech Synthesis with Transformer Network,Transformer-TTS,2019.01,AAAI,A,https://arxiv.org/abs/1809.08895,https://blog.csdn.net/weixin_42721167/article/details/119639442,https://github.com/linslime/Transformer-TTS
,WaveGlow: A Flow-based Generative Network for Speech Synthesis,WaveGlow,2019,ICASSP,B,https://arxiv.org/abs/1811.00002,https://blog.csdn.net/weixin_42721167/article/details/115493648,https://github.com/NVIDIA/waveglow
,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,DEEP VOICE 3,2018,ICLR,,https://arxiv.org/abs/1710.07654,https://blog.csdn.net/weixin_42721167/article/details/114479658,
,Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining,Voice Transformer Network,,Interspeech,C,https://arxiv.org/abs/1912.06813,https://blog.csdn.net/weixin_42721167/article/details/114759156,
,WaveNet: A Generative Model for Raw Audio,WaveNet,2016,,,https://arxiv.org/abs/1609.03499,https://blog.csdn.net/weixin_42721167/article/details/112593690,https://github.com/linslime/WaveNet
,HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,HHiFi-GAN,2020,NeurIPS,A,https://arxiv.org/abs/2010.05646,https://blog.csdn.net/weixin_42262721/article/details/120796935,https://github.com/linslime/hifi-gan
,Pixel Recurrent Neural Networks,Pixel,2016,ICML,A,https://arxiv.org/abs/1601.06759,https://blog.csdn.net/Blackoutdragon/article/details/131163328,https://github.com/linslime/PixelCNN
,Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech,VITS,2021,ICML,A,https://arxiv.org/abs/2106.06103,https://blog.csdn.net/zzfive/article/details/127061469 ,https://github.com/linslime/vits
,NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality,NaturalSpeech,2022.05,TPAMI,A,https://arxiv.org/abs/2205.04421,https://blog.csdn.net/weixin_44649780/article/details/134829743,https://github.com/heatz123/naturalspeech
,NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers,NaturalSpeech 2,2023.04,,,https://arxiv.org/abs/2304.09116,https://blog.csdn.net/weixin_44649780/article/details/134828929,https://github.com/lucidrains/naturalspeech2-pytorch
,VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild,VoiceCraft,2024,ACL,A,https://arxiv.org/abs/2403.16973,https://blog.csdn.net/matt45m/article/details/140153776,https://github.com/jasonppy/voicecraft
,VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design,VITS2,2023,Interspeech,C,https://arxiv.org/abs/2307.16430,https://blog.csdn.net/qq_39247879/article/details/132168384,
,PITS: Variational Pitch Inference without Fundamental Frequency for End-to-End Pitch-controllable TTS,PITS,2023,,,https://arxiv.org/abs/2302.12391,https://github.com/anonymous-pits/pits,
,MSMC-TTS: Multi-Stage Multi-Codebook VQ-VAE Based Neural TTS,MSMC-TTS,2023.05,TASLP,B,https://ieeexplore.ieee.org/abstract/document/10114504,,
