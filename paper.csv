id,标题,模型,时间,期刊/会议,CCF等级,原文,翻译,代码
1,Tacotron: Towards End-to-End Speech Synthesis,Tacotron,2017.03,Interspeech,C,https://arxiv.org/abs/1703.10135,https://blog.csdn.net/weixin_42721167/article/details/113406997,https://github.com/linslime/tacotron
2,Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions,Tacotron2,2018,ICASSP,B,https://arxiv.org/abs/1712.05884,https://blog.csdn.net/weixin_43916891/article/details/127463829 https://blog.csdn.net/weixin_42721167/article/details/114377171,https://github.com/linslime/Tacotron2-PyTorch
3,"FastSpeech: Fast, Robust and Controllable Text to Speech",FastSpeech,2019,NeurIPS,A,https://arxiv.org/abs/1905.09263,https://blog.csdn.net/weixin_42721167/article/details/118226439,https://github.com/linslime/FastSpeech
4,FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,FastSpeech2,2021,ICLR,,https://arxiv.org/abs/2006.04558,https://blog.csdn.net/weixin_42721167/article/details/118226439,https://github.com/linslime/FastSpeech2
5,Neural Speech Synthesis with Transformer Network,Transformer-TTS,2019.01,AAAI,A,https://arxiv.org/abs/1809.08895,https://blog.csdn.net/weixin_42721167/article/details/119639442,https://github.com/linslime/Transformer-TTS
6,WaveGlow: A Flow-based Generative Network for Speech Synthesis,WaveGlow,2019,ICASSP,B,https://arxiv.org/abs/1811.00002,https://blog.csdn.net/weixin_42721167/article/details/115493648,https://github.com/NVIDIA/waveglow
7,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,DEEP VOICE 3,2018,ICLR,,https://arxiv.org/abs/1710.07654,https://blog.csdn.net/weixin_42721167/article/details/114479658,
8,Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining,Voice Transformer Network,,Interspeech,C,https://arxiv.org/abs/1912.06813,https://blog.csdn.net/weixin_42721167/article/details/114759156,
9,WaveNet: A Generative Model for Raw Audio,WaveNet,2016,,,https://arxiv.org/abs/1609.03499,https://blog.csdn.net/weixin_42721167/article/details/112593690,https://github.com/linslime/WaveNet
10,HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,HHiFi-GAN,2020,NeurIPS,A,https://arxiv.org/abs/2010.05646,https://blog.csdn.net/weixin_42262721/article/details/120796935,https://github.com/linslime/hifi-gan
11,Pixel Recurrent Neural Networks,Pixel,2016,ICML,A,https://arxiv.org/abs/1601.06759,https://blog.csdn.net/Blackoutdragon/article/details/131163328,https://github.com/linslime/PixelCNN
12,Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech,VITS,2021,ICML,A,https://arxiv.org/abs/2106.06103,https://blog.csdn.net/zzfive/article/details/127061469 ,https://github.com/linslime/vits
13,NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality,NaturalSpeech,2022.05,TPAMI,A,https://arxiv.org/abs/2205.04421,https://blog.csdn.net/weixin_44649780/article/details/134829743,https://github.com/heatz123/naturalspeech
14,NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers,NaturalSpeech 2,2023.04,,,https://arxiv.org/abs/2304.09116,https://blog.csdn.net/weixin_44649780/article/details/134828929,https://github.com/lucidrains/naturalspeech2-pytorch
15,VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild,VoiceCraft,2024,ACL,A,https://arxiv.org/abs/2403.16973,https://blog.csdn.net/matt45m/article/details/140153776,https://github.com/jasonppy/voicecraft
16,VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design,VITS2,2023,Interspeech,C,https://arxiv.org/abs/2307.16430,https://blog.csdn.net/qq_39247879/article/details/132168384,
17,PITS: Variational Pitch Inference without Fundamental Frequency for End-to-End Pitch-controllable TTS,PITS,2023,,,https://arxiv.org/abs/2302.12391,https://github.com/anonymous-pits/pits,
18,MSMC-TTS: Multi-Stage Multi-Codebook VQ-VAE Based Neural TTS,MSMC-TTS,2023.05,TASLP,B,https://ieeexplore.ieee.org/abstract/document/10114504,,
19,StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models,StyleTTS 2,2024,NeurIPS,A,https://arxiv.org/abs/2306.07691,,
20,P-Flow: A Fast and Data-Efficient Zero-Shot TTS through Speech Prompting,P-Flow,2024,NeurIPS,A,https://proceedings.neurips.cc/paper_files/paper/2023/hash/eb0965da1d2cb3fbbbb8dbbad5fa0bfc-Abstract-Conference.html,,
