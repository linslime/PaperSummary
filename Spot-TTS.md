## ABSTRACT
There is a huge development in the field of speech synthesis that is not only close to human naturalness, but is also capable of instant voice cloning with little data, and is highly accessible with pre-trained models available. Naturally, the potential flood of generated content raises the need for synthetic speech detection and watermarking. We propose a collaborative training scheme that embeds specific watermarks into speech synthesized by different users and enables the detection of these watermarks , but remains transparent to a human listener. Specifically, we employs a straightforward and effective GAN based on HiFi-GAN to restructure audio and embed a watermark, then trains a detection model to detect the type of watermark in the audio. Finally, listening tests demonstrate that collaborative training has little adverse effect on perceptual quality of vocoded speech. 

## INTRODUCTION
Modern speech synthesis systems have achieved nearly human level naturalness and are capable of zero-shot voice cloning from a few seconds of adaptation data. Open-source implementations, sharing pre-trained models, and good software packaging has made voice cloning with TTS easily accessible also outside the research community. Furthermore, the use of voice cloning technology as a service has recently emerged as a popular past-time on the Internet. With this growing user base, the amount of generated speech in the wild is increasing, which poses a risk of casually created misinformation and malicious deepfakes. 

Research on audio deepfake detection focuses mostly on passive protection using machine learning methods, which is also referred to as speech anti-spoofing. This scenario assumes that defenders have no prior knowledge of what attackers will use to generate the audio deepfake. The attackers can use any speech generation models to create the audio deepfake, while the defenders only have a limited number of audio deepfake types in the training set, which does not necessarily cover those from the attackers. Hence, the key question for the defender is how to develop a detection model on the basis of the limited training data and make it generalize to unseen deepfakes. 

Research outcomes from, for example, the ASVspoof and Audio Deep synthesis Detection (ADD) challenges, have demonstrated some deep learning-based detectors can detect certain unseen deepfakes in the benchmark datasets with error rates smaller than 5%. However, many detectors were found to be vulnerable to spurious features in the training set and generalize poorly to data from different domains. Even though the generalization capability may be improved by including more diverse training data, the long-term equilibrium of this adversarial game of passive audio deepfake detection is yet to be seen. Attackers can always create audio deepfake from newer and stronger speech generation models. 

Generative adversarial networks (GANs) take a mirrored perspective on playing the adversarial game of detection and generation. In this setting, a discriminator network attempts to classify between samples from the real and generated data distributions, while another network, the Generator synthesizes new samples and tries to spoof the discriminator into classifying the generated samples as real. The theoretical equilibrium for the GAN game is that the generator learns to match the real data distribution exactly, and discriminating between real and generated samples becomes impossible. Despite practical challenges with finite model capacity, numerics, and unstable training dynamics, GAN-based synthesis methods can be used for realistic speech waveform synthesis. In particular, HiFi-GAN is widely used as a high-quality neural vocoder in text-to-speech synthesis and voice-conversion. 

The adversarial perspective remains highly relevant in defence against black-hat attack scenarios. However, the intended use of a generative model is often not malicious, and deceptive realism is merely a side-product of a high-quality system. In these use cases, the generative model provided is likely happy to comply to any regulation and make an active effort to embed a watermark  into their generated model outputs as such. Moreover, a unique watermark could even be embedded  into audio for each user, allowing identification of user by simply detecting the watermark type from the restructured audio. The relevance of watermarking is amplified by the common use of pre-trained models and hosted services: if a model has built-in watermarking that is not trivial to remove and does not affect the perceptual quality of the output, most users will not make an effort to remove the watermark. 

This paper proposes a collaborative training scheme that tasks a generative model to watermark its output in specific ways for different users to be more easily detectable by a specific classifier without degrading the perceptual quality. The experiments use HiFi-GAN as the generative model and ASVspoof 2021 challenge baseline countermeasure models as watermark detector models. Additionally, the detection performance under additive noise and time-stretching is shown to improve by differentiable augmentation during training. Results show that collaborative training consistently improves the detection performance compared to the corresponding passively trained countermeasure model.

Watermarks can be evaluated using multiple characteristics, including robustness, perceptibility, and applications [14]. Some applications, such as proof-of-ownership or object identification, require a watermark payload with high enough bit count to encode sufficient information, but this paper focuses on a simple zero-bit watermark: the watermark is present in synthetic speech and not present in natural speech. Sometimes researchers use the terms watermarking and fingerprinting interchangeably. We use fingerprint to denote the summary of the perceptible information in the carrier speech signal, such as linguistic content, expression, speaker identity, or acoustic channel information. In contrast, a watermark aims to convey hidden information and not be perceptible to the human listener.

Audio watermarking usually consists of an embedder and a detector. The embedder embeds a watermark or message, e.g., pseudorandom numbers or a hash, into the input audio, and the detector verifies the message’s existence in a watermarked audio. Typical algorithms using DSP include adding pseudo-noise in the temporal or spectral domain (a.k.a. spread spectrum watermarking [15]), phase coding [16], and echo hiding [17]. Some recent methods also implement the embedded and detector using DNNs [18, 19]. 

A notable approach that combines DSP and statistics is patchwork watermarking [20]. When implemented in the spectral domain, this algorithm embeds a single bit m in the spectrum of an audio frame by selecting two sets of frequency bins and changing their amplitude values in opposite ways. Let sk be the spectral amplitude at the k-th frequency bin and A and B be the two sets of frequency bins. The algorithm can be written as

For generative models in the image domain, watermarking the training data with standard DSP techniques has been shown to transfer to GAN outputs [21]. Yu et al. [22] propose a jointly trained watermark encoder-decoder scheme for GANs. This is closely related to our work, both in motivation (“from passive classifiers to proactive fingerprinting”), and implementation (their Generator acts as a watermark embedding model). Main differences are different domains and our work adds augmentation for robustness.

## EXPERIMENTS
###  1. Datasets
The Voice Cloning Toolkit (VCTK) [30] corpus is used for all the speech data in the experiments. VCTK has a data split protocol for ASVspoof aimed at evaluation purposes [4], but we deemed the training set too small for training the synthesis system. Instead, we opted for a custom 80-10-10% split to training, validation, and test sets. Split details are provided with the source code. Each subset has distinct speakers, but has overlaps in text content. Noise data for augmentation consists of the noise subset from the MUSAN database [29]. We apply a 80-10-10% split and use unseen noise samples during testing.
### 2. Training details
Following HiFi-GAN, we use the AdamW optimizer with learning rate 2e-4, β1 = 0.8, β2 = 0.99 and learning rate decay with exponential decay factor 0.999. Training segements are padded or randomly cropped to 8,192 samples with LFCC-LCNN and 65,536 samples with RawNet. In Collaborator models, the gradients are allowed to flow back from the WM to G, while in Observer models the gradient is detached. Each model configuration is trained for 50 epochs, amounting to approximately 110k iterations. Note that the HiFi-GAN paper [13] reports training for 2.5M iterations, which does yield higher synthesis quality. This work focuses on demonstrating the relative benefit of collaborative training over baseline observer training in many scenarios. We believe the current setup offers a reasonable trade-off between the computational cost of training many systems, and the perceptual quality of generated speech. The various model configurations were trained on available hardware from a pool of GPUs consisting of NVIDIA A100, V100 and P100 models.
###  3. Patchwork watermark baseline
As a DSPbaseline, patchwork watermarking is applied to vocoded speech from a HiFi-GAN trained without detector collaboration. The patchwork watermarking algorithm described in Section 2 is included for reference. The open-sourced toolkit Audiowmark 3 is used due to its high-quality implementation with error-correction in watermarking detection. A fixed-length 128 bit text string is watermarked. The hyper-parameter d was selected for each test utterance through grid search. Given the range between 0.01 and 0.2, the value of d was decided so that the detector outputs the correct watermark without other hypothesis. During test conditions, the watermarked audio is added with noise or stretched before sent to the watermark detector.
### 4. Listening test
We conducted a mean opinion score (MOS) test to evaluate the perceptual effect of the proposed method. Listeners were asked to rate the naturalness of the presented speech samples on a five-point scale ranging from 1 (bad) to 5 (excellent). The listening test stimuli consist of 50 utterances selected randomly from test set. After pooling together test utterances from each system, the stimuli were randomly batched to 100 sample listening sessions, and each batch was rated by at least five listeners on the Prolific crowd sourcing platform. After screening, 3884 to talratings by 35 listeners were used in the analysis. Table 2 shows MOS values witht-statistic based confidence intervals. Differences between vocoded systems are not statistically significant.
### 5
Table 1 displays test set equal error rates (EER) for a range of systems. When training watermark detector models jointly with the generator, collaborative training consistently outperforms conventional observer training. This remains consistent over the detector model type, optional augmentation during training, and different test conditions from clean to time-stretching and/or additive noise. Al LFCC-LCNN confgurations struggle with addivive noise, whereas collaborative training with RawNet and data augmentation still performs well under noise (EER 4.03).However, combining noise with time-stretching remains a challenging for both LFCC-LCNN and RawNet detectors even when the models were trained with matching data augmentation

Pre-trained models struggle as watermark detectors, as listed in the bottom part of Table 1. In collaborative training, the synthesis model manages to embed some detectable information in clean conditions, but detection performance deteriorates when noise is added. In a zero-shot scenario (i.e., pre-trainer observer) the performance is near chance level for both LFCC-LCNN and RawNet. It appears that the Generator’s attempt to fool the Discriminator transfers to the ASVspoof pre-trained baselines, which have not been trained on HiFi-GAN vocoded speech.

The DSP-based watermarking algorithm achieves a low error rate in the clean condition since the strength d was decided to allow perfect watermark detection in this condition. However, there are a few utterances in which the embedded watermark failed to be detected given the largest d. Its error rate increases when the watermarked audio is stretched, even when the provided compensation for playback was used. The performance degrades dramatically when additive noise is applied. Note that the patchwork baseline is not one-to-one comparable to the detector models, since baseline watermark uses a 128-bit payload and does not output detection scores required for EER calculation.

A central limitation of the current experimental setup is the focus on neural vocoding. Real-world voice cloning applications use a full text-to-speech or voice conversion system. Nevertheless, we are optimistic on the transferability of training on vocoded speech based on recent results in the ASVspoof scenario [23]. However, security critical applications still need to follow an adversarial countermeasure protocol. Collaborative watermarking is only useful when the generative model user has an incentive to watermark their model outputs. Furthermore, collaborative training is not limited to GANs. Any deep generative model with differentiable sampling (including diffusion models [31, 32]) can collaborate with a detector model to improve the odds of detection.