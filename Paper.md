# PaperSummary
___
## Tacotron: Towards End-to-End Speech Synthesis
原文：https://arxiv.org/abs/1703.10135  
翻译：https://blog.csdn.net/weixin_42721167/article/details/113406997  
代码：https://github.com/linslime/tacotron  
### Tacotron  
#### Tacotron模型结构：  
![img.png](plot/Tacotron.png)  
#### CBHG模型结构：  
![img.png](plot/CBHG.png)  
___
## Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions
原文：https://arxiv.org/abs/1712.05884  
翻译：https://blog.csdn.net/weixin_43916891/article/details/127463829  
     https://blog.csdn.net/weixin_42721167/article/details/114377171  
代码：https://github.com/linslime/Tacotron2-PyTorch  
### Tacotron2
#### Tacotron模型结构
![img.png](plot/Tacotron2.png)  
![img.png](plot/Tacotron2_2.png)   
![img_1.png](plot/Tacotron2_3.png)
___
## FastSpeech: Fast, Robust and Controllable Text to Speech
原文：https://arxiv.org/abs/1905.09263  
翻译：https://blog.csdn.net/weixin_42721167/article/details/118226439  
代码：https://github.com/linslime/FastSpeech  
### FastSpeech
#### FastSpeech模型结构
![img.png](plot/FastSpeech.png)
___
## FastSpeech 2: Fast and High-Quality End-to-End Text to Speech
原文：https://arxiv.org/abs/2006.04558  
翻译：https://blog.csdn.net/weixin_42721167/article/details/118226439  
代码：https://github.com/linslime/FastSpeech2
### FastSpeech2
#### FastSpeech模型结构
![img.png](plot/FastSpeech2.png)
___
## Neural Speech Synthesis with Transformer Network
原文：https://arxiv.org/abs/1809.08895  
翻译：https://blog.csdn.net/weixin_42721167/article/details/119639442  
代码：https://github.com/linslime/Transformer-TTS  
### Transformer-TTS
#### Transformer-TTS模型结构
![img.png](plot/Transformer-TTS.png)
___
## WaveGlow: A Flow-based Generative Network for Speech Synthesis
原文：https://arxiv.org/abs/1811.00002  
翻译：https://blog.csdn.net/weixin_42721167/article/details/115493648  
代码：https://github.com/NVIDIA/waveglow
### WaveGlow
#### WaveGlow模型结构
![img.png](plot/WaveGlow.png)
___
## Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning
原文：https://arxiv.org/abs/1710.07654  
翻译：https://blog.csdn.net/weixin_42721167/article/details/114479658
### DEEP VOICE 3
#### DEEP VOICE 3模型结构
![img.png](plot/DEEP_VOICE_3.png)
#### Convolution Block
![img_1.png](plot/Convolution_Block.png)
#### Attention Block
![img_2.png](plot/Attention_Block.png)
#### WORLD Block
![img_3.png](plot/WORLD_Block.png)
___
## Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining
原文：https://arxiv.org/abs/1912.06813  
翻译：https://blog.csdn.net/weixin_42721167/article/details/114759156
### Voice Transformer Network
#### Voice Transformer Network模型结构
![img.png](plot/Voice_Transformer_Network.png)
#### 训练过程
![img_1.png](plot/VTN_train.png)
___
## WaveNet: A Generative Model for Raw Audio
原文：https://arxiv.org/abs/1609.03499  
翻译：https://blog.csdn.net/weixin_42721167/article/details/112593690  
代码：https://github.com/linslime/WaveNet
### WaveNet
#### WaveNet模型结构
![img.png](plot/WaveNet.png)
#### 因果卷积
![img_1.png](plot/CausalConvolution.png)
#### 扩大卷积
![img_2.png](plot/DilatedConvolution.png)
___
## HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
原文：https://arxiv.org/abs/2010.05646  
翻译:https://blog.csdn.net/weixin_42262721/article/details/120796935  
代码：https://github.com/linslime/hifi-gan
### HHiFi-GAN
#### Generator
![img.png](plot/HiFi-GAN-Generative.png)
#### Discriminator
![img_1.png](plot/HiFi-GAN-Discriminator.png)
___
## Pixel Recurrent Neural Networks
原文：https://arxiv.org/abs/1601.06759  
翻译：https://blog.csdn.net/Blackoutdragon/article/details/131163328  
代码：https://github.com/linslime/PixelCNN
___
## Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech
原文：https://arxiv.org/abs/2106.06103  
翻译：https://blog.csdn.net/zzfive/article/details/127061469  
代码：https://github.com/linslime/vits
### VITS
#### VITS模型训练和推演过程
![img.png](plot/VITS.png)
#### 框图描述了随机持续时间预测器的 (a) 训练过程和 (b) 推理过程。随机持续时间预测器的主要构建块是 (c) 膨胀和深度可分离的卷积残差块
![img_1.png](plot/VITS1.png)
#### (a) 条件编码器和 (b) 随机持续时间预测器中使用的耦合层的架构
![img_2.png](plot/VITS2.png)
___
## NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality
原文：https://arxiv.org/abs/2205.04421  
翻译：https://blog.csdn.net/weixin_44649780/article/details/134829743  
代码：https://github.com/heatz123/naturalspeech
### NaturalSpeech
#### NaturalSpeech模型训练和推演过程
![img.png](plot/NaturalSpeech.png)
___
## NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers
原文：https://arxiv.org/abs/2304.09116  
翻译：https://blog.csdn.net/weixin_44649780/article/details/134828929  
代码：https://github.com/lucidrains/naturalspeech2-pytorch
### NaturalSpeech 2
#### NaturalSpeech 2模型结构
![img.png](plot/NaturalSpeech2.png)
![img_1.png](plot/NaturalSpeech2_2.png)
___
## VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild
原文：https://arxiv.org/abs/2403.16973  
翻译：https://blog.csdn.net/matt45m/article/details/140153776  
代码：https://github.com/jasonppy/voicecraft  
### VoiceCraft
#### VoiceCraft模型结构
![img.png](plot/VoiceCraft.png)
___
## VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design
原文：https://arxiv.org/abs/2307.16430  
翻译：https://blog.csdn.net/qq_39247879/article/details/132168384
### VITS2
#### VITS2模型结构
![img.png](img.png)
___
## PITS: Variational Pitch Inference without Fundamental Frequency for End-to-End Pitch-controllable TTS
原文：https://arxiv.org/abs/2302.12391  
代码：https://github.com/anonymous-pits/pits
### PITS
#### PITS模型结构
![img_1.png](img_1.png)
