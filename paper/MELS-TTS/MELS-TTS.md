# Mels-Tts : Multi-Emotion Multi-Lingual Multi-Speaker Text-To-Speech System Via Disentangled Style Tokens
___
## ABSTRACT
本文提出了一种多情感、多语言和多说话人的文本转语音 (MELS-TTS) 系统，采用解开的风格标记来实现有效的情感传递。在包含各种属性（例如情绪状态、说话者身份和语言风格）的语音中，解开这些元素对于高效的多情感、多语言和多说话人的 TTS 系统至关重要。为了实现这一目的，我们建议利用单独的风格标记来解开情感、语言、说话者和残留信息，这受到全局风格标记 (GST) 的启发。通过注意机制，每个风格标记从目标语音中学习其各自的语音属性。我们提出的方法在客观和主观评价中都提高了性能，展示了能够生成具有多种情感的跨语言语音的能力，即使是来自中性的源说话者，同时保留说话者的身份。  

索引词——语音合成、情感语音合成、情感传递、跨语言语音合成
##  1. INTRODUCTION
随着神经文本转语音 (TTS) 系统 [1–5] 成功生成类似人类的语音，对多情感或多语言 TTS 系统的需求正在增加。在现实世界中，要求目标说话者以多种情感或语言讲话是一项挑战。先前的研究 [6–10] 探索了情感 TTS 系统，特别关注将情感从多情感源说话者转移到中性目标说话者。此外，一些研究调查了跨语言 TTS，旨在生成各种语言的语音，同时保留目标说话者的身份 [11–13]。  

情感传递或跨语言 TTS 系统从源说话者那里学习情感或语言信息，并将其传递给目标说话者。由于内容、说话者身份、情感、语言和说话风格等语音属性固有的交织，这个过程非常复杂。正确分离这些属性对于将所需的语音属性正确地传递给目标说话者至关重要。当这些语音属性带有适当的标签时，解开它们变得更加简单 [14, 15]。在这些语音属性中，情感在不同语音中表现出明显的复杂性和多变性。我们的初步实验表明，基于标签的 TTS 难以处理看不见的标签组合，尤其是在跨语言情况下合成情感语音。  

为了克服这些解开难题，人们探索了基于参考的 TTS 系统 [16–21]。在 [19] 中，情感信息以无监督的方式从参考语音中提取出来。尽管如此，通过基于参考的 TTS 系统 [9,21] 确保从参考语音中独家分离和提取情感信息仍然具有挑战性。为了解决这一限制，之前的几项研究提出利用辅助分类器 [22] 或对抗性分类器 [11,13] 来指导嵌入向量学习预期信息。虽然类似的方法已应用于基于参考的 TTS 系统 [9]，但目前仅限于单语场景。最近的一项研究 [10] 提出最小化情感、语言和说话人身份属性之间的相互信息，以解决跨语言场景。  

在我们的实证观察中，我们注意到话语中语音属性的强度存在变化。例如，某些话语可能会突出强调说话者的身份，但缺乏情感表达。因此，当语音中没有清楚地传达预期信息时，通过基于参考的系统从参考语音中提取预期信息就成为一项具有挑战性的任务。这种限制严重阻碍了准确提取预期信息，尤其是当不同语音属性的强度在单个话语中波动时。  

为了解决基于参考的 TTS 系统中的解缠结挑战，我们提出了一种有效的多情感、多语言和多说话人 TTS (MELS-TTS) 系统。在 MELS-TTS 系统中，情感编码器的设计受到全局风格标记 (GST) 系统 [16] 的启发，GST 系统是一种著名的基于参考的风格控制 TTS 系统。我们采用 GST 的方法来学习目标语音中风格标记和参考嵌入的相似性。为了提高 MELS-TTS 系统的解缠结能力，我们提出了一种带有解缠结风格标记的情感编码器，即四种不同的风格标记：说话人、语言、残差和情感。这些标记被明确指定为表示相应的语音属性。在训练阶段，MELS-TTS 系统通过注意力机制学习每个解缠结风格标记对目标语音的影响。这样，通过单独学习各种语音属性的影响，就可以成功解开它们。在推理阶段，我们从解开的风格标记中选择性地选择所需的情感标记。这些标记用于通过注意力从所需的参考嵌入中提取情感嵌入，从而促进我们系统中强大的情感传递。客观和主观评价都证实，我们的 MELS-TTS 系统在多语言和多说话者场景中的情感传递方面优于其他基于参考的 TTS 系统。  
![img.png](img.png)  
##  2. PROPOSED METHOD
###  2.1. Overall architecture
我们提出的方法 MELS-TTS 1 基于 Tacotron 变体 [23]，如图 1 所示。文本编码器将音素序列处理为文本嵌入，解码器使用该嵌入自回归生成声学特征。在每个解码器步骤中，预网络处理目标声学特征的前一帧，这些特征在推理过程中被预测。预网络输出与之前的注意上下文连接在一起，产生当前上下文向量。这驱动了解码器 RNN 堆栈，预测目标声学特征和停止标记。  

MELS-TTS 的主要区别在于对情感、说话者和语言信息的处理。从情感编码器中提取的情感嵌入具有解开的风格标记，并与文本嵌入连接。说话者和语言 ID 通过查找表进行处理，有助于解开风格标记。经过线性层后，说话者和语言嵌入与解码器的预网络输出连接，提供对说话者和语言的控制。总体而言，所提出方法的训练目标与 Tacotron 变体 [23] 相同，没有额外的损失。  
###  2.2. Emotion encoder with disentangled style tokens
我们采用了 [16] 中描述的参考编码器和风格注意机制。参考编码器将目标语音的梅尔频谱图处理成参考嵌入，作为风格注意机制的查询。对于风格注意机制的键和值，我们提出了代表四种语音属性的解耦风格标记：说话者、语言、情感和残差。  
#### 2.2.1. Disentangled style tokens
情感标记集 情感标记集被配置为仅从参考嵌入中学习情感信息。我们为每种情感组织情感标记集，以确保平衡学习，以解决不平衡的情感数据库。每个情感标记集都包含一组随机初始化的嵌入，以捕捉情感类别中的各种细微差别。使用情感 ID，根据目标梅尔频谱图的情感选择相应的标记集。  

说话者标记 我们设计说话者标记来辅助情感嵌入，确保说话者信息与参考嵌入分离。在训练期间，说话者标记用于从参考嵌入中学习说话者信息，利用说话者查找表中的输出嵌入。通过在推理过程中从解开的风格标记中排除说话者标记，我们可以从参考嵌入中提取情感嵌入，而无需合并说话者信息。  

语言标记 语言标记的功能与说话者标记类似，旨在将语言细节与参考嵌入分开。语言标记利用语言查找表输出进行训练，但在推理中被省略。 

残差标记集 除了说话者和语言属性之外，我们还承认非情感信息中还存在其他细节，称为残差信息。为了适应这种多样性，残差标记集包含随机初始化的嵌入。与说话者和语言标记类似，它在推理过程中被排除，以将残差信息与参考嵌入分开。  
####  2.2.2. Style attention
训练为了从参考嵌入 R ∈ R1× dR 中捕获不同的语音信息，我们使用所有解开的风格标记 TA ∈ RNA× dT 作为风格注意机制中的键和值。这些标记包括选定的目标情感标记集 TE ∈ RNE× dT、说话人标记 TS ∈ RNS× dT、语言标记 TL ∈ RNL× dT 和残差标记集 TR ∈ RNR× dT。TE 是从情感标记集中选择的，其组成可能根据训练数据中情感的多样性而变化。在我们的实验中，我们使用四个情感标记集 {Tn,Th,Ts,Ta}，分别代表中性、快乐、悲伤和愤怒的情感标记集。NE、NS、NL 和 NR 表示情感标记集、说话人标记、语言标记和残差标记集中标记的数量，它们的总和等于 NA。对于风格注意力机制，我们采用具有 n 个头的多头注意力机制 [24]，如下所示：  
![img_1.png](img_1.png)  
其中 Attention(Q,K,V ) = softmax(QKT/√dk)V，dk是每个头部的维度。投影参数 W(i)Q ,W(i)和 W(i)K , V 是针对第 i 个头部进行学习的，WO 将所有头部的注意力输出串联起来投影到情感嵌入上。  

推理对于特定于情绪的显着性，我们停用说话者、语言和残差标记集。我们使用选定的情绪标记集 TE 作为等式 (1) 和 (2) 中风格注意的键和值，而不是 TA。  
### 2.3. Inference of MELS-TTS
为了合成跨情绪的语音，我们首先确定每个情绪的代表性情绪嵌入以进行推理。如第 2.2.2 节所述，我们从情绪标记集中选择所需的情绪标记集。接下来，我们计算所有训练数据库话语的情绪嵌入，并获取每种情绪的平均情绪嵌入。最接近该平均值的话语的情绪嵌入充当代表性情绪嵌入。从经验上讲，使用现有话语的情绪嵌入优于使用平均情绪嵌入。有了代表性情绪嵌入，推理过程中就不需要参考语音了，我们可以稳定地合成具有所需情绪的语音。所需的代表性情绪嵌入与文本编码器的输出连接在一起，所需的说话者和语言 ID 通过查找表和线性层进行处理，然后输入解码器。  
##  3. EXPERIMENTS
### 3.1. Experimental setup
为了评估跨语言跨说话人的情绪传递，我们使用包含韩语和英语录音的多语言语音数据库进行了实验。韩语数据库 [25] 包含 42 位母语人士对七种不同情绪的录音，我们重点关注四种情绪类别：中性、快乐、悲伤和愤怒。该数据库包含约 271,000 条话语，总计约 230 小时，情绪比例不平衡。对于测试集，选择了四个只具有中性情绪的说话者。对于英语数据库，我们使用了 VCTK [26] 数据库，其中包含来自 108 位说话者的约 43,000 条话语，跨度约 25 小时。对于测试集，我们随机选择了二十个句子。

所有语音样本均下采样至 24 kHz。我们采用了 Bunched LPCNet2 [27] 神经声码器，使用 22 维 LPCNet 特征作为目标声学特征，包括 20 个 Bark 倒谱系数、音调周期和音调相关性。参考编码器输入是 80 维对数梅尔频谱图，使用 1024 窗口大小和 256 跳跃大小提取。

MELS-TTS 系统的整体架构基于 [23]，用三个卷积块替换文本编码器中的 CBHG 块，每个卷积块具有 512 个通道和 5 个内核，后面跟着一个包含 128 个单元的双向 LSTM 层。

![img_2.png](img_2.png)

![img_3.png](img_3.png)

每个卷积块包括一个一维卷积层、ϵ为10−5的实例归一化[28]和速率为0.5的dropout。参考编码器架构与[16]相似。在我们的风格注意机制中，dk为64，nh为4，输出嵌入维度为256。NE和NR均为5，且正交初始化。NS和NL均设置为1。说话人和语言的查找表和线性层分别具有64和256的维度。我们使用Adam优化器[29]对网络进行了1000K步的训练，批处理大小为64，初始学习率为0.001，每100K步衰减0.5倍。

我们比较了三个基线系统：基于标签的 TTS (LB) 系统、GST 系统 [16] 和带有情感分类器的 GST 系统 (GST-C) [6]。与 MELS-TTS 系统类似，我们在基线系统中加入了说话人和语言查找表以及线性层。所有系统都建立在 [23] 的基础上。在 LB 系统中，情感标签通过查找表转换为情感嵌入。
###  3.2. Subjective evaluation
我们在跨语言情感传递场景中进行了三项主观平均意见分数 (MOS) 测试，以测量自然度、说话者相似度和情感相似度。韩语和英语语音样本均进行了评估。在韩语测试中，19 位母语专家评估了语音样本，而英语测试在 Amazon Mechanical Turk 平台上进行，分别有 46、116 和 119 名参与者进行自然度、说话者相似度和情感相似度评估。

对于自然度，参与者将语音样本的评分分为 1：差、2：差、3：一般、4：好和 5：优秀。在相似度测试中，他们将语音样本的评分分为 1：完全不同、2：略微相似、3：相似、4：非常相似和 5：几乎相同。请注意，大于 2 的分数表示它们与参考语音相似。参与者被要求在相似度测试中忽略语音的内容或语言，因为参考和合成语音样本使用的语言不同。还对不同说话者的真值 (GT) 语音样本进行了相似度测试，以设置情感相似度的上限分数。由于训练数据中没有英语情感语音，我们使用外部英语语音样本作为英语情感相似度测试的参考语音。

![img_4.png](img_4.png)  
表 3：来自英语源语者的合成韩语语音中四种情绪的情绪分类准确率 [%]。平均值表示整体情绪的平均准确率。

表 1 和表 2 显示了四种情绪的跨语言合成语音样本的 MOS 测试结果。表 1 展示了来自英语源语者的合成韩语语音样本的结果，其中所提出的方法在自然度和情感相似度方面优于基线方法。在说话人相似度测试中，所提出的方法表现接近最佳。LB 系统在自然度和情感相似度测试中排名第二，得益于韩语情感数据库进行情感传递。表 2 显示了来自韩语源语者的合成英语情感语音样本，所提出的方法在自然度和情感相似度方面表现最佳。包括 GT 在内的英语整体表现低于韩语，这可能是因为英语训练数据库中不存在情感数据以及语言之间的领域差异，而使用外部英语情感语音样本作为参考语音加剧了这种差异。

####  3.3. Objective evaluation
为了进一步验证我们的方法，我们使用预先训练的情感分类器评估了跨语言情感合成语音的情感准确性，该分类器在与我们的实验相同的韩语情感数据库上进行训练。分类器架构由一个线性层和三个双向 GRU 层组成，最后以线性投影来生成独热矢量情感标签。与 [30] 类似，最后一个 GRU 层的第一个和最后一个的输出被连接起来并投影到最后一个线性层。每个双向 GRU 层都有 256 个单元。第一个和最后一个线性层的维度分别为 128 和 4。我们评估了 320 个话语，每个情感 20 个样本，这些话语由四个英语源说话者为每个 TTS 系统合成。表 3 中的结果表明，我们的方法非常接近 GT 案例的性能，表明其有效性，如表 1 所示。

####  3.4. Ablation study
在我们的方法中，非情感标记在训练过程中起着至关重要的作用，可以分离非情感信息。为了证明这一点，我们进行了一项实验，在实验中，我们甚至在训练阶段就从所提出的系统中排除了说话者、语言和残差 (SLR) 标记，并评估了其性能。表 3 的最后一行显示了没有 SLR 标记时情感分类准确度的下降。然而，即使没有 SLR 标记，所提出方法的性能仍然优于基线系统，证明了利用情感标记集的有效性。

图 2 描绘了使用 t-SNE [31] 的情感嵌入，其中从测试数据库中随机选择了 700 个话语，每个情感都有。如果没有 SLR 标记（图 2a），一些话语的聚类效果很差。相比之下，所提出的系统（图 2b）实现了情感嵌入的完美聚类。这表明 SLR 标记有助于所提出的系统解开语音属性，并允许情感嵌入专注于情感信息。

####  4. CONCLUSION
在本文中，我们提出了 MELS-TTS 系统，利用分离的风格标记来表示说话者、语言、情感和残留信息。在训练过程中，风格注意机制会学习从参考语音中分离语音属性，从而促进目标说话者声音中的跨语言情感传递。评估证实了 MELS-TTS 能够从不同语言的中性说话者生成跨语言情感语音。